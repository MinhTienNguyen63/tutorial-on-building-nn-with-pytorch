Tutorial: Setting Up and Training an Image Classifier with PyTorch

In this tutorial, we'll walk through the process of training a simple neural network to classify handwritten digits using the MNIST dataset.
Step 1: Import Dependencies
Before you begin, ensure you have the necessary libraries installed:
bash
pip install torch torchvision Pillow

Then, we start by importing the required modules:
python
# import torch 
# from PIL import Image
# from torch import nn, save, load
# from torch.optim import Adam
# from torch.utils.data import DataLoader
# from torchvision import datasets
# from torchvision.transforms import ToTensor

Step 2: Load the Dataset
We'll use the MNIST dataset, which consists of grayscale images of handwritten digits (0-9):
python
# train = datasets.MNIST(root="data", download=True, train=True, transform=ToTensor())
# dataset = DataLoader(train, 32)

The DataLoader splits the data into batches of size 32 for training.
Step 3: Define the Neural Network
Our neural network will consist of three convolutional layers followed by a fully connected layer:
python
# class ImageClassifier(nn.Module): 
#     def __init__(self):
#         super().__init__()
#         self.model = nn.Sequential(
#             nn.Conv2d(1, 32, (3,3)), 
#             nn.ReLU(),
#             nn.Conv2d(32, 64, (3,3)), 
#             nn.ReLU(),
#             nn.Conv2d(64, 64, (3,3)), 
#             nn.ReLU(),
#             nn.Flatten(), 
#             nn.Linear(64*(28-6)*(28-6), 10)  
#         )

    # def forward(self, x): 
    #     return self.model(x)

Step 4: Setup Training Components
We'll use the Adam optimizer and CrossEntropyLoss as our loss function:
python
# clf = ImageClassifier().to('cpu') # Move model to CPU
# opt = Adam(clf.parameters(), lr=1e-3)
# loss_fn = nn.CrossEntropyLoss() 

Note: If you have a GPU, you can replace 'cpu' with 'cuda' to train on the GPU.
Step 5: Training Loop
The main training loop where we iterate over the dataset, compute predictions, calculate loss, and update our model's weights:
python
# for epoch in range(10): # train for 10 epochs
#     for batch in dataset: 
#         X, y = batch 
#         X, y = X.to('cpu'), y.to('cpu') # Move data to CPU
#         yhat = clf(X) 
#         loss = loss_fn(yhat, y) 

#         # Apply backpropagation 
#         opt.zero_grad()
#         loss.backward() 
#         opt.step() 

#     print(f"Epoch:{epoch} loss is {loss.item()}")

Step 6: Save and Load the Model
After training, we save our model weights for future use:
python
# with open('model_state.pt', 'wb') as f: 
#     save(clf.state_dict(), f) 

To load the saved model:
python
# with open('model_state.pt', 'rb') as f: 
#     clf.load_state_dict(load(f))  

Step 7: Make Predictions
Load an image and make predictions:
python
# img = Image.open('img_3.jpg') 
# img_tensor = ToTensor()(img).unsqueeze(0).to('cpu') # Ensure the image is grayscale and 28x28 pixels
# print(torch.argmax(clf(img_tensor)))

Note: Ensure the input image is a grayscale image with size 28x28 pixels for accurate predictions. Use img.convert('L').resize((28, 28)) if necessary.

